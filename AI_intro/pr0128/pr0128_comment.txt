이번 코드는 전이학습과 데이터의 절대적인 양이 적을 때 과적합을 방지하는 기법에 대한 코드다.
데이터가 적은 시베리안 허스키 vs 늑대 분류 사례처럼 데이터가 적을 경우 전이학습과 데이터 증강기법을 사용하면 
과적합을 방지할 수 있다. 그 이유는 전이학습은 사전 학습된 모델을 통해 일반적인 특징을 재사용함으로써 학습률을 높인다.
데이터 증강의 경우 학습 데이터를 변형 ex) 좌우반전, 무작위 그림 지우기, 채도변경 등 여러 기법을 사용하여 
적은 실데이터양을 변형한 데이터를 집어넣어 학습할 수 있는 데이터의 양을 키우는 방향으로 과적합을 방지하는 기법이다.
